{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pypdf langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import glob\n",
    "\n",
    "# Specify the PDF file directory.\n",
    "directory_path = \"D:/VSCODE/paper_code/PDF\"\n",
    "\n",
    "# Get the paths of all PDF files in the directory.\n",
    "pdf_files = glob.glob(f\"{directory_path}/*.pdf\")\n",
    "\n",
    "all_docs = []\n",
    "\n",
    "for file_path in pdf_files:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    all_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "# Here is the personal OpenAI API key for using the related APIs\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xx-xxxx-xxxxxxxxxxx\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_chroma langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Set the chunk size and overlap for the text splitter.\n",
    "text_splitter = None\n",
    "splits = None\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=10)\n",
    "splits = text_splitter.split_documents(all_docs)\n",
    "\n",
    "# Define a function to process the documents in batches.\n",
    "def batch_documents(documents, batch_size):\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        yield documents[i:i + batch_size]\n",
    "\n",
    "max_batch_size = 5461\n",
    "\n",
    "vectorstore = None\n",
    "\n",
    "# Process in batches and create vector storage.\n",
    "for batch in batch_documents(splits, max_batch_size):\n",
    "    if vectorstore is None:\n",
    "        vectorstore = Chroma.from_documents(documents=batch, embedding=OpenAIEmbeddings())\n",
    "    else:\n",
    "        vectorstore.add_documents(documents=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever.\n",
    "retriever = None\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 788})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"Note that the terms 'model', 'part', 'CAD file' and 'component' are equivalent. \"\n",
    "    \"'Planar surface', 'Flat surface', 'Level plane', 'Even plane', 'Even surface', 'Flat area' and 'flat plane' are the same. \"\n",
    "    \"'Round hole', 'Circular hole', 'Cylinder hole' and 'cylindrical hole' are the same.\"\n",
    "    \"'curved surface', 'Curved area', 'Curved plane', 'Curved profile', 'Curved face', 'Arched surface' and 'Curved shape' are the same.\"\n",
    "    \"'straight edge', 'Straight boundary', 'Linear edge', 'Straight line', 'Straight border', 'Straight perimeter' and 'Direct edge' are the same.\"\n",
    "    \"\\n\\n\"\n",
    "    \"When comparing multiple parameters, structure your answer as follows:\\n\"\n",
    "    \"1. Parameter A: [brief description]\\n\"\n",
    "    \"2. Parameter B: [brief description]\\n\"\n",
    "    \"3. Parameter C: [brief description]\\n\"\n",
    "    \"Conclude with a brief summary if necessary.\"\n",
    "    \"\\n\\n\"\n",
    "    \"When asked to compare the size of parameters and output the maximum or minimum value, structure your answer as follows:\\n\"\n",
    "    \"1. Compare Parameter A, B, C, etc.\\n\"\n",
    "    \"2. State which parameter is the largest or smallest.\\n\"\n",
    "    \"Example: 'The largest parameter is Parameter B with a value of X.'\"\n",
    "    \"\\n\\n\"\n",
    "    \"When asked to find more than one largest parameters, structure your answer as follows:\\n\"\n",
    "    \"State which are the two largest parameters.\\n\"\n",
    "    \"Example: 'The two largest parameters are Parameter B with a value of X and Parameter C with a value of Y.'\"\n",
    "    \"\\n\\n\"\n",
    "    \"A complex model contains many curved surfaces and edges, and has many holes.\\n\"\n",
    "    \"A complex model also includes more historical designs, such as more sketches and more extrusions.\\n\"\n",
    "    \"A simple model mostly consists of straight edges and flat planes, with no holes or very few holes.\\n\"\n",
    "    \"A simple model means fewer surfaces, fewer holes, small mean Gaussian curvature and mean curvature.\\n\"\n",
    "    \"A simpler model also means less design history, such as fewer sketches and fewer extrusions.\\n\"\n",
    "    \"Example: 'The complex model is A: [brief description].'\"\n",
    "    \"\\n\\n\"\n",
    "    \"'NewBodyFeatureOperation' and 'NewBody' are the same. \"\n",
    "    \"\\n\\n\"\n",
    "    \"If an image of a model needs to be drawn, then focus on referencing the design history information for that model. \"\n",
    "    \"\\n\\n\"\n",
    "    \"Queries about model 'similarity' can be answered in terms of the similarity of the various parameters of the model,\" \n",
    "    \"such as volume, surface area, \"\n",
    "    \"proportion of straight edges, number of holes, and whether the design steps are similar.\"\n",
    "    \"The response begins with an explanation of which models are more or less similar, followed by a brief analysis.\"\n",
    "    \"Example: 'The similarity between Model A and Model B is very high: [brief description].'\"\n",
    "    \"\\n\\n\"\n",
    "    \"'SymmetricFeatureExtentType' and 'Symmetric' are the same. \"\n",
    "    \"'OneSideFeatureExtentType' and 'OneSide' are the same. \"\n",
    "    \"'TwoSideFeatureExtentType' and 'TwoSide' are the same. \"\n",
    "    \"\\n\\n\"\n",
    "    \"When asked about the design history of the part, which is DEEP DATA, first answer how many sketches the part contains and\" \n",
    "    \"show the information in the sketch. Then answer how many extrudes the part contains and show the information in the extrude.\\n\"\n",
    "    \"Example: 'This model contains 3 sketches, each containing the following lines:\"\n",
    "    \"1. Sketch 1:\"\n",
    "    \"   - Line ending at (1.1, 1.1)\"\n",
    "    \"   - Line ending at (1.1, -1.1)\"\n",
    "    \"   - Line ending at (-1.1, -1.1)\"\n",
    "    \"   - Line ending at (-1.1, 1.1)\"\n",
    "    \"Regarding the extrude operations:\"\n",
    "    \"1. Extrude 1:\"\n",
    "    \"   - Operation: NewBodyFeatureOperation\"\n",
    "    \"   - Direction: (0, 0, 0)\"\n",
    "    \"   - Origin: (0, 0, 0)\"\n",
    "    \"   - Scale: 1\"\n",
    "    \"   - Extent one: 0.05\"\n",
    "    \"   - Extent two: 0.0\"\n",
    "    \"   - Extent type: OneSideFeatureExtentType'\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = None\n",
    "results = rag_chain.invoke({\"input\": \"Which two models are more similar?\"})\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
